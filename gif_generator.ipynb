{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 136\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved animation to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Create and run the simulator\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     simulator \u001b[38;5;241m=\u001b[39m \u001b[43mAudioTerminalSimulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     simulator\u001b[38;5;241m.\u001b[39mgenerate_gif()\n",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m, in \u001b[0;36mAudioTerminalSimulator.__init__\u001b[0;34m(self, width, height, num_frames)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterference_color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)  \u001b[38;5;66;03m# Blue interference\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Initialize the TokenLinear model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mTokenLinearGL\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Input features for audio processing\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Output features (matches terminal width)\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Number of frequency components\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Characters for visualization\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchars \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m█\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmediumHigh\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m▓\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrongNeg\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m□\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     37\u001b[0m }\n",
      "File \u001b[0;32m~/Positional-Token-Linear/token_linear.py:16\u001b[0m, in \u001b[0;36mTokenLinearGL.__init__\u001b[0;34m(self, in_features, out_features, num_tokens)\u001b[0m\n\u001b[1;32m     14\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, num_tokens)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [num_tokens, 1]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m freqs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [1, 8] different frequencies\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m angles \u001b[38;5;241m=\u001b[39m positions \u001b[38;5;241m*\u001b[39m freqs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241m.\u001b[39mpi  \u001b[38;5;66;03m# [num_tokens, 8]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m pos_enc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39msin(angles), torch\u001b[38;5;241m.\u001b[39mcos(angles)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [num_tokens, 16]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m, pos_enc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from token_linear import TokenLinearGL\n",
    "import math\n",
    "from pathlib import Path\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "class AudioTerminalSimulator:\n",
    "    def __init__(self, width=800, height=600, num_frames=60):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_frames = num_frames\n",
    "        self.bg_color = (0, 0, 0)  # Black background\n",
    "        self.text_color = (0, 255, 0)  # Green text\n",
    "        self.wave_color = (255, 255, 0)  # Yellow wave\n",
    "        self.interference_color = (0, 0, 255)  # Blue interference\n",
    "        \n",
    "        # Initialize the TokenLinear model\n",
    "        self.model = TokenLinearGL(\n",
    "            in_features=64,  # Input features for audio processing\n",
    "            out_features=50,  # Output features (matches terminal width)\n",
    "            num_tokens=32    # Number of frequency components\n",
    "        )\n",
    "        \n",
    "        # Characters for visualization\n",
    "        self.chars = {\n",
    "            'solid': '█',\n",
    "            'mediumHigh': '▓',\n",
    "            'medium': '▒',\n",
    "            'low': '░',\n",
    "            'empty': ' ',\n",
    "            'strongPos': '∎',\n",
    "            'weakPos': '∙',\n",
    "            'weakNeg': '∘',\n",
    "            'strongNeg': '□'\n",
    "        }\n",
    "\n",
    "    def generate_audio_data(self, frame):\n",
    "        \"\"\"Simulate audio data with multiple frequency components\"\"\"\n",
    "        t = frame / self.num_frames\n",
    "        \n",
    "        # Create a mixture of frequencies\n",
    "        base_freq = 2 * math.pi * t\n",
    "        frequencies = torch.linspace(1, 10, 64)\n",
    "        phases = torch.tensor([base_freq * f for f in frequencies])\n",
    "        \n",
    "        # Generate complex waveform\n",
    "        audio_data = torch.sin(phases) + 0.5 * torch.sin(2 * phases)\n",
    "        audio_data += 0.3 * torch.sin(3 * phases + math.pi/4)\n",
    "        \n",
    "        # Normalize\n",
    "        audio_data = audio_data / audio_data.abs().max()\n",
    "        return audio_data.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process one frame of audio data through the model\"\"\"\n",
    "        audio_data = self.generate_audio_data(frame)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.model(audio_data)\n",
    "            \n",
    "        # Scale output to [-1, 1] range\n",
    "        output = output.squeeze(0)\n",
    "        output = output / output.abs().max()\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def map_to_chars(self, values, char_set):\n",
    "        \"\"\"Map numerical values to ASCII characters\"\"\"\n",
    "        result = ''\n",
    "        for v in values:\n",
    "            v = v.item()\n",
    "            if v > 0.8:\n",
    "                result += char_set['solid']\n",
    "            elif v > 0.4:\n",
    "                result += char_set['mediumHigh']\n",
    "            elif v > 0:\n",
    "                result += char_set['medium']\n",
    "            elif v > -0.4:\n",
    "                result += char_set['low']\n",
    "            else:\n",
    "                result += char_set['empty']\n",
    "        return result\n",
    "\n",
    "    def create_frame_image(self, frame_num):\n",
    "        \"\"\"Create a single frame as PIL Image\"\"\"\n",
    "        # Create new image with black background\n",
    "        image = Image.new('RGB', (self.width, self.height), self.bg_color)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        # Process audio data\n",
    "        output = self.process_frame(frame_num)\n",
    "        \n",
    "        # Split output into two visualization layers\n",
    "        wave_data = output[:len(output)//2]\n",
    "        interference_data = output[len(output)//2:]\n",
    "        \n",
    "        # Convert to ASCII art\n",
    "        wave_line = self.map_to_chars(wave_data, self.chars)\n",
    "        interference_line = self.map_to_chars(interference_data, self.chars)\n",
    "        \n",
    "        # Draw terminal content\n",
    "        y_offset = 50\n",
    "        draw.text((40, y_offset), f\"[{wave_line}]\", fill=self.wave_color)\n",
    "        draw.text((40, y_offset + 30), f\"[{interference_line}]\", fill=self.interference_color)\n",
    "        \n",
    "        # Add terminal prompt\n",
    "        draw.text((40, y_offset + 80), \"> _\", fill=self.text_color)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def generate_gif(self, output_path=\"audio_terminal.gif\"):\n",
    "        \"\"\"Generate GIF from frames\"\"\"\n",
    "        frames = []\n",
    "        \n",
    "        print(\"Generating frames...\")\n",
    "        for i in range(self.num_frames):\n",
    "            frame = self.create_frame_image(i)\n",
    "            frames.append(frame)\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Generated frame {i}/{self.num_frames}\")\n",
    "        \n",
    "        print(\"Saving GIF...\")\n",
    "        frames[0].save(\n",
    "            output_path,\n",
    "            save_all=True,\n",
    "            append_images=frames[1:],\n",
    "            duration=50,  # 50ms per frame (20 fps)\n",
    "            loop=0\n",
    "        )\n",
    "        print(f\"Saved animation to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create and run the simulator\n",
    "    simulator = AudioTerminalSimulator()\n",
    "    simulator.generate_gif()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
